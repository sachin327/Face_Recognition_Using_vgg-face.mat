{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    IMAGE_WIDTH = 224\n",
    "    IMAGE_HEIGHT = 224\n",
    "    COLOR_CHANNELS = 3\n",
    "    NOISE_RATIO = 0.6\n",
    "    MEANS = np.array([129.1863, 104.7624, 93.5940]).reshape((1,1,1,3)) \n",
    "def load_vgg_model(path):\n",
    "    \"\"\"1 is conv1_1 (3, 3, 3, 64)\n",
    "        2 is relu1_1\n",
    "        3 is conv1_2 (3, 3, 64, 64)\n",
    "        4 is relu1_2    \n",
    "        5 is pool1\n",
    "        6 is conv2_1 (3, 3, 64, 128)\n",
    "        7 is relu2_1\n",
    "        8 is conv2_2 (3, 3, 128, 128)\n",
    "        9 is relu2_2\n",
    "        10 is pool2\n",
    "        11 is conv3_1 (3, 3, 128, 256)\n",
    "        12 is relu3_1\n",
    "        13 is conv3_2 (3, 3, 256, 256)\n",
    "        14 is relu3_2\n",
    "        15 is conv3_3 (3, 3, 256, 256)\n",
    "        16 is relu3_3\n",
    "        17 is pool3\n",
    "        18 is conv4_1 (3, 3, 256, 512)\n",
    "        19 is relu4_1\n",
    "        20 is conv4_2 (3, 3, 512, 512)\n",
    "        21 is relu4_2\n",
    "        22 is conv4_3 (3, 3, 512, 512)\n",
    "        23 is relu4_3\n",
    "        24 is pool4\n",
    "        25 is conv5_1 (3, 3, 512, 512)\n",
    "        26 is relu5_1\n",
    "        27 is conv5_2 (3, 3, 512, 512)\n",
    "        28 is relu5_2\n",
    "        29 is conv5_3 (3, 3, 512, 512)\n",
    "        30 is relu5_3\n",
    "        31 is pool5\n",
    "        32 is fullyconnected (7, 7, 512, 4096)\n",
    "        33 is relu6\n",
    "        34 is fullyconnected (1, 1, 4096, 4096)\n",
    "        35 is relu7\n",
    "        36 is fullyconnected (1, 1, 4096, 2622)\n",
    "        37 is softmax\n",
    "    \"\"\"\n",
    "    \n",
    "    vgg = scipy.io.loadmat(path)\n",
    "\n",
    "    vgg_layers = vgg['layers']\n",
    "    \n",
    "    def _weights(layer, expected_layer_name):\n",
    "        \"\"\"\n",
    "        Return the weights and bias from the VGG model for a given layer.\n",
    "        \"\"\"\n",
    "        wb = vgg_layers[0][layer][0][0][2]\n",
    "        W = wb[0][0]\n",
    "        b = wb[0][1]\n",
    "        layer_name = vgg_layers[0][layer][0][0][1][0]\n",
    "        assert layer_name == expected_layer_name\n",
    "        return W, b\n",
    "\n",
    "    def _relu(conv2d_layer):\n",
    "        \"\"\"\n",
    "        Return the RELU function wrapped over a TensorFlow layer. Expects a\n",
    "        Conv2d layer input.\n",
    "        \"\"\"\n",
    "        return tf.nn.relu(conv2d_layer)\n",
    "\n",
    "    def _conv2d(prev_layer, layer, layer_name):\n",
    "        \"\"\"\n",
    "        Return the Conv2D layer using the weights, biases from the VGG\n",
    "        model at 'layer'.\n",
    "        \"\"\"\n",
    "        W, b = _weights(layer, layer_name)\n",
    "        W = tf.constant(W)\n",
    "        b = tf.constant(np.reshape(b, (b.size)))\n",
    "        return tf.nn.conv2d(prev_layer,W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
    "    def _conv2d1(prev_layer, layer, layer_name):\n",
    "        \"\"\"\n",
    "        Return the Conv2D layer using the weights, biases from the VGG\n",
    "        model at 'layer'.\n",
    "        \"\"\"\n",
    "        W, b = _weights(layer, layer_name)\n",
    "        W = tf.constant(W)\n",
    "        b = tf.constant(np.reshape(b, (b.size)))\n",
    "        return tf.nn.conv2d(prev_layer,W, strides=[1, 1, 1, 1], padding='VALID') + b\n",
    "\n",
    "    def _conv2d_relu(prev_layer, layer, layer_name):\n",
    "        \"\"\"\n",
    "        Return the Conv2D + RELU layer using the weights, biases from the VGG\n",
    "        model at 'layer'.\n",
    "        \"\"\"\n",
    "        return _relu(_conv2d(prev_layer, layer, layer_name))\n",
    "\n",
    "    def _pool(prev_layer):\n",
    "        \"\"\"\n",
    "        Return the MaxPooling layer.\n",
    "        \"\"\"\n",
    "        return tf.nn.max_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Constructs the graph model.\n",
    "    graph = {}\n",
    "    graph['input']   = tf.Variable(np.zeros((1, CONFIG.IMAGE_HEIGHT, CONFIG.IMAGE_WIDTH, CONFIG.COLOR_CHANNELS)), dtype = 'float32')\n",
    "    graph['conv1_1']  = _conv2d_relu(graph['input'], 0, 'conv1_1')\n",
    "    graph['conv1_2']  = _conv2d_relu(graph['conv1_1'], 2, 'conv1_2')\n",
    "    graph['pool1'] = _pool(graph['conv1_2'])\n",
    "    graph['conv2_1']  = _conv2d_relu(graph['pool1'], 5, 'conv2_1')\n",
    "    graph['conv2_2']  = _conv2d_relu(graph['conv2_1'], 7, 'conv2_2')\n",
    "    graph['pool2'] = _pool(graph['conv2_2'])\n",
    "    graph['conv3_1']  = _conv2d_relu(graph['pool2'], 10, 'conv3_1')\n",
    "    graph['conv3_2']  = _conv2d_relu(graph['conv3_1'], 12, 'conv3_2')\n",
    "    graph['conv3_3']  = _conv2d_relu(graph['conv3_2'], 14, 'conv3_3')\n",
    "    graph['pool3'] = _pool(graph['conv3_3'])\n",
    "    graph['conv4_1']  = _conv2d_relu(graph['pool3'], 17, 'conv4_1')\n",
    "    graph['conv4_2']  = _conv2d_relu(graph['conv4_1'], 19, 'conv4_2')\n",
    "    graph['conv4_3']  = _conv2d_relu(graph['conv4_2'], 21, 'conv4_3')\n",
    "    graph['pool4'] = _pool(graph['conv4_3'])\n",
    "    graph['conv5_1']  = _conv2d_relu(graph['pool4'], 24, 'conv5_1')\n",
    "    graph['conv5_2']  = _conv2d_relu(graph['conv5_1'], 26, 'conv5_2')\n",
    "    graph['conv5_3']  = _conv2d_relu(graph['conv5_2'], 28, 'conv5_3')\n",
    "    graph['pool5'] = _pool(graph['conv5_3'])\n",
    "    graph['fc6']  = _relu(_conv2d1(graph['pool5'], 31, 'fc6'))\n",
    "    graph['fc7']  = _relu(_conv2d1(graph['fc6'], 33, 'fc7'))\n",
    "    graph['fc8']  = _relu(_conv2d1(graph['fc7'], 35, 'fc8'))\n",
    "    \n",
    "    \n",
    "    return graph\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_normalize_image(image):\n",
    "    \"\"\"\n",
    "    Reshape and normalize the input image (content or style)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reshape image to mach expected input of VGG16\n",
    "    image = np.reshape(image, ((1,) + image.shape))\n",
    "    \n",
    "    # Substract the mean to match the expected input of VGG16\n",
    "    #image = image - CONFIG.MEANS\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_(path):\n",
    "    image = Image.open(path)\n",
    "    image = image.resize((224,224))\n",
    "    image=np.array(image)\n",
    "    image = reshape_and_normalize_image(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'conv1_1': <tf.Tensor 'Relu:0' shape=(1, 224, 224, 64) dtype=float32>,\n",
      "    'conv1_2': <tf.Tensor 'Relu_1:0' shape=(1, 224, 224, 64) dtype=float32>,\n",
      "    'conv2_1': <tf.Tensor 'Relu_2:0' shape=(1, 112, 112, 128) dtype=float32>,\n",
      "    'conv2_2': <tf.Tensor 'Relu_3:0' shape=(1, 112, 112, 128) dtype=float32>,\n",
      "    'conv3_1': <tf.Tensor 'Relu_4:0' shape=(1, 56, 56, 256) dtype=float32>,\n",
      "    'conv3_2': <tf.Tensor 'Relu_5:0' shape=(1, 56, 56, 256) dtype=float32>,\n",
      "    'conv3_3': <tf.Tensor 'Relu_6:0' shape=(1, 56, 56, 256) dtype=float32>,\n",
      "    'conv4_1': <tf.Tensor 'Relu_7:0' shape=(1, 28, 28, 512) dtype=float32>,\n",
      "    'conv4_2': <tf.Tensor 'Relu_8:0' shape=(1, 28, 28, 512) dtype=float32>,\n",
      "    'conv4_3': <tf.Tensor 'Relu_9:0' shape=(1, 28, 28, 512) dtype=float32>,\n",
      "    'conv5_1': <tf.Tensor 'Relu_10:0' shape=(1, 14, 14, 512) dtype=float32>,\n",
      "    'conv5_2': <tf.Tensor 'Relu_11:0' shape=(1, 14, 14, 512) dtype=float32>,\n",
      "    'conv5_3': <tf.Tensor 'Relu_12:0' shape=(1, 14, 14, 512) dtype=float32>,\n",
      "    'fc6': <tf.Tensor 'Relu_13:0' shape=(1, 7, 7, 4096) dtype=float32>,\n",
      "    'fc7': <tf.Tensor 'Relu_14:0' shape=(1, 7, 7, 4096) dtype=float32>,\n",
      "    'fc8': <tf.Tensor 'add_15:0' shape=(1, 7, 7, 2622) dtype=float32>,\n",
      "    'input': <tf.Variable 'Variable_2:0' shape=(1, 224, 224, 3) dtype=float32>,\n",
      "    'pool1': <tf.Tensor 'MaxPool:0' shape=(1, 112, 112, 64) dtype=float32>,\n",
      "    'pool2': <tf.Tensor 'MaxPool_1:0' shape=(1, 56, 56, 128) dtype=float32>,\n",
      "    'pool3': <tf.Tensor 'MaxPool_2:0' shape=(1, 28, 28, 256) dtype=float32>,\n",
      "    'pool4': <tf.Tensor 'MaxPool_3:0' shape=(1, 14, 14, 512) dtype=float32>,\n",
      "    'pool5': <tf.Tensor 'MaxPool_4:0' shape=(1, 7, 7, 512) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "model = load_vgg_model(\"vgg-face.mat\")\n",
    "pp.pprint(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.InteractiveSession()\n",
    "model = load_vgg_model(\"vgg-face.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(model['input'].assign(open_('images/DJ_Khaled.jpg')))\n",
    "out=model['fc8']\n",
    "DJ_Khaled=sess.run(out)\n",
    "sess.run(model['input'].assign(open_('images/sunder.jpg')))\n",
    "out=model['fc8']\n",
    "sunder=sess.run(out)\n",
    "sess.run(model['input'].assign(open_('images/selena.jpg')))\n",
    "out=model['fc8']\n",
    "selena=sess.run(out)\n",
    "sess.run(model['input'].assign(open_('images/mark.jpg')))\n",
    "out=model['fc8']\n",
    "mark=sess.run(out)\n",
    "sess.run(model['input'].assign(open_('images/elon.jpg')))\n",
    "out=model['fc8']\n",
    "elon=sess.run(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}\n",
    "database[\"DJ_Khaled\"] = DJ_Khaled[0][0][0]\n",
    "database[\"selena\"] = selena[0][0][0]\n",
    "database[\"mark\"] = mark[0][0][0]\n",
    "database[\"sunder\"] = sunder[0][0][0]\n",
    "database[\"elon\"] = elon[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: who_is_it\n",
    "\n",
    "def who_is_it(image_path, database, model):\n",
    "    \n",
    "    sess.run(model['input'].assign(open_(image_path)))\n",
    "    out=model['fc8']\n",
    "    a=sess.run(out)\n",
    "    min_dist = 10000\n",
    "    \n",
    "    # Loop over the database dictionary's names and encodings.\n",
    "    for (name, db_enc) in database.items():\n",
    "        \n",
    "        dist = np.linalg.norm(a[0][0][0]-db_enc)\n",
    "\n",
    "        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (â‰ˆ 3 lines)\n",
    "        if dist<min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
    "        \n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's DJ_Khaled, the distance is 96.87281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(96.87281, 'DJ_Khaled')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who_is_it(\"images/unknown4.jpg\", database, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
